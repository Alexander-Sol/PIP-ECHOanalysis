{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "import bisect\n",
    "#import altair as alt\n",
    "pd.options.mode.chained_assignment = None\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8606258759661092"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling factor for entrapment calculations, based on the ratio on the number of entrapment peptide sequences and human peptide sequences in the database\n",
    "\n",
    "scaling_factor = 1 + 3105275 / 3608159\n",
    "scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local path to files downloaded from PRIDE\n",
    "data_path = \"D:\\\\PIP_ECHO_PRIDE\\\\\"\n",
    "\n",
    "\n",
    "entrapment_seq_path = data_path + r\"Proteomes\\EntrapmentProteinPeptideSequences_50percent.txt\"\n",
    "with open(entrapment_seq_path) as f:\n",
    "    entrapment_seqs = f.readlines()\n",
    "\n",
    "entrapment_seqs_set = set()\n",
    "for seq in entrapment_seqs:\n",
    "    entrapment_seqs_set.add(seq.replace(\"\\n\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary linking protein accessions to their species of origin (For MaxQuant analysis)\n",
    "accession_dict = dict()\n",
    "\n",
    "yeast_fasta_sequences = SeqIO.parse(open(data_path + r\"Proteomes\\uniprot_SCerevisiae_6k_03_2024.fasta\"),'fasta')\n",
    "yeast_records = list(yeast_fasta_sequences)\n",
    "for record in yeast_records:\n",
    "    accession_dict[record.id.split('|')[1]] = 'Yeast'\n",
    "\n",
    "human_fasta_sequences = SeqIO.parse(open(data_path + r\"Proteomes\\uniprot_HSapiens_80k_03_2024.fasta\"),'fasta')\n",
    "human_records = list(human_fasta_sequences)\n",
    "for record in human_records:\n",
    "    accession_dict[record.id.split('|')[1]] = 'Human'\n",
    "\n",
    "human_fasta_sequences = SeqIO.parse(open(data_path + r\"Proteomes\\ConcatenatedHumanEntrapmentProteins_50percent.fasta\"),'fasta')\n",
    "human_records = list(human_fasta_sequences)\n",
    "for record in human_records:\n",
    "    accession_dict[record.id.split('|')[1]] = 'Human'\n",
    "    accession_dict[record.id] = 'Human'\n",
    "\n",
    "ecoli_fasta_sequences = SeqIO.parse(open(data_path + r\"Proteomes\\uniprot_Ecoli_4k_03_2024.fasta\"),'fasta')\n",
    "ecoli_records = list(ecoli_fasta_sequences)\n",
    "for record in ecoli_records:\n",
    "    accession_dict[record.id.split('|')[1]] = 'Ecoli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fdp_old_flash(o_peaks_path, c_peaks_path, censored_psm_path, human_file_pattern = \"_1x02nguL_\",\n",
    "                   foreign_species = 'Yeast', rt_delta = 0.25):\n",
    "\n",
    "    # calculate the error rate for (presumably) native human transfers\n",
    "    peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
    "    \n",
    "    peaks = peaks.loc[~peaks[\"Protein Group\"].str.contains(\"DECOY\")]\n",
    "    peaks = peaks.loc[peaks[\"File Name\"].str.contains(human_file_pattern)]\n",
    "    peaks[\"Organism\"] = peaks.apply(get_organisms, axis = 1)\n",
    "\n",
    "    msms_detected_yeast_peaks = peaks.loc[(peaks[\"Peak Detection Type\"] == \"MSMS\") &\n",
    "                           (peaks[\"Organism\"].str.contains(foreign_species))]\n",
    "    msms_detected_yeast_peaks.drop_duplicates(subset = [\"Full Sequence\"], keep = 'first', inplace = True)\n",
    "    msms_yeast_seqs = set(msms_detected_yeast_peaks[\"Full Sequence\"].tolist())\n",
    "\n",
    "    peaks = peaks.loc[(peaks[\"Peak Detection Type\"] == \"MBR\")]\n",
    "\n",
    "    human_peaks = peaks.loc[peaks[\"Organism\"].str.contains('Human')]\n",
    "    # Our entrapment database has a bunch of scrambled sequences appended to the end of the DB, which is why we're checking for them\n",
    "    entrapment_peaks = human_peaks.loc[human_peaks[\"Full Sequence\"].isin(entrapment_seqs_set)]\n",
    "    human_peaks = human_peaks.loc[~human_peaks[\"Base Sequence\"].isin(entrapment_seqs_set)]\n",
    "    \n",
    "    human_count = human_peaks.shape[0]\n",
    "    arabida_count = entrapment_peaks.shape[0]\n",
    "\n",
    "    yeast_peaks = peaks.loc[peaks[\"Organism\"].str.contains(foreign_species)]\n",
    "    yeast_peaks = yeast_peaks.loc[~yeast_peaks[\"Organism\"].str.contains('Human')]\n",
    "    yeast_count = yeast_peaks.shape[0]\n",
    "    \n",
    "    msms_yeast_count = sum(yeast_peaks[\"Full Sequence\"].isin(msms_yeast_seqs))\n",
    "    yeast_count = yeast_count - msms_yeast_count\n",
    "\n",
    "\n",
    "    scaled_arabida = arabida_count * scaling_factor\n",
    "    nper_results = get_nper_old_flash(censored_psm_path, o_peaks_path, c_peaks_path, rt_delta)\n",
    "    scaled_nper = human_count * nper_results[\"error_rate\"]\n",
    "\n",
    "    total = human_count + yeast_count + arabida_count\n",
    "\n",
    "    fper = 100 * yeast_count / total\n",
    "    nper = 100 * scaled_nper / total\n",
    "    fder = 100 * scaled_arabida / total\n",
    "\n",
    "    false_discovery_proportion = fper + nper + fder\n",
    "\n",
    "    results = dict(\n",
    "        {\n",
    "            \"human\": human_count,\n",
    "            \"foreign\": yeast_count,\n",
    "            \"arabida\": arabida_count,\n",
    "            \"total\": total,\n",
    "            \"scaled_arabida\": scaled_arabida,\n",
    "            \"scaled_nper\": scaled_nper,\n",
    "            \"sensitivity\": nper_results[\"sensitivity\"],\n",
    "            \"fper\": fper,\n",
    "            \"nper\": nper,\n",
    "            \"fder\": fder,\n",
    "            \"false_discovery_proportion\": false_discovery_proportion\n",
    "        }\n",
    "    )\n",
    "    return results\n",
    "\n",
    "def get_organisms(row):\n",
    "    accesions = row[\"Protein Group\"].split(\";\")\n",
    "    organisms = []\n",
    "    for a in accesions:\n",
    "        if a in accession_dict:\n",
    "            organisms.append(accession_dict[a])\n",
    "        elif (\"ENTRAPMENT\" in a):\n",
    "            organisms.append(\"Arabida\")\n",
    "    return \";\".join(organisms)\n",
    "\n",
    "def get_nper_old_flash(censored_path, old_peak_path, new_peak_path, rt_delta = 0.25):\n",
    "    # Read in the list of peptides that were censored\n",
    "    censored_psms = pd.read_csv(censored_path, sep = '\\t')\n",
    "    # Select the ones that were quantified in the initial FlashLFQ analysis\n",
    "    original_peaks = pd.read_csv(old_peak_path, sep = '\\t')\n",
    "    original_peaks = original_peaks[original_peaks[\"Peak RT Apex\"] != \"-\"]\n",
    "    censored_peaks = pd.merge(censored_psms, original_peaks, how = \"inner\", left_on=[\"File Name\", \"Full Sequence\"], right_on=[\"File Name\", \"Full Sequence\"])\n",
    "    censored_peaks = censored_peaks[[\"File Name\", \"Full Sequence\", \"Peak RT Start\", \"Peak RT Apex\", \"Peak RT End\", \"Peak Charge\", \"Peak intensity\"]]\n",
    "    # This will allow for comparison later, as all the new peaks were take from files named in this way\n",
    "    censored_peaks[\"File Name\"] = censored_peaks[\"File Name\"].astype(str) + \"-censored\" \n",
    "\n",
    "    # Merge the old and new results\n",
    "    new_peaks = pd.read_csv(new_peak_path, sep = '\\t')\n",
    "    new_peaks = new_peaks.loc[(new_peaks[\"Peak Detection Type\"] == \"MBR\")]\n",
    "    new_peaks = new_peaks[[\"File Name\", \"Full Sequence\", \"Peak RT Start\", \"Peak RT Apex\", \"Peak RT End\", \"Peak Charge\",  \"Peak intensity\", \"MBR Score\"]]\n",
    "    peak_join = pd.merge(censored_peaks, new_peaks, how = \"inner\", left_on=[\"File Name\", \"Full Sequence\"], right_on=[\"File Name\", \"Full Sequence\"])\n",
    "\n",
    "    peak_join_no_dup = peak_join.drop_duplicates(subset = [\"File Name\", \"Full Sequence\"], keep = 'first')\n",
    "    censored_peaks_no_dup = censored_peaks.drop_duplicates(subset = [\"File Name\", \"Full Sequence\"], keep = 'first')\n",
    "    sensitivity = peak_join_no_dup.shape[0] / censored_peaks_no_dup.shape[0]\n",
    "\n",
    "    #compare the old and new results (here, 1 means the match, 0 means they dont)\n",
    "    peak_join[\"Agreement\"] = peak_join.apply(lambda x: check_overlap_time(x, rt_delta), axis = 1)\n",
    "\n",
    "    if(peak_join.shape[0] == 0):\n",
    "        return dict({\n",
    "            \"sensitivity\": 0,\n",
    "            \"error_rate\": 0} )\n",
    "\n",
    "    peak_join.sort_values(by = 'MBR Score', ascending=False, inplace=True)\n",
    "    peak_join[\"good_transfers\"] = (peak_join[\"Agreement\"] == 1).cumsum()\n",
    "    peak_join[\"bad_transfers\"] = (peak_join[\"Agreement\"] == 0).cumsum()\n",
    "    peak_join[\"error_rate\"] = peak_join.apply(calculateErrorRate, axis = 1)\n",
    "\n",
    "    results = dict(\n",
    "        {\n",
    "            \"sensitivity\": sensitivity,\n",
    "            \"error_rate\": peak_join[\"error_rate\"].iloc[-1]\n",
    "        }\n",
    "\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "# Native Peak Error Rate functions\n",
    "def check_overlap_time(table, rt_delta = 0.25):\n",
    "    try:\n",
    "        pip_apex = float(table[\"Peak RT Apex_y\"])\n",
    "        ms_apex = float(table[\"Peak RT Apex_x\"])\n",
    "    except:\n",
    "        return -1\n",
    "    if(abs(pip_apex-ms_apex) < rt_delta):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def calculateErrorRate(table):\n",
    "    return table[\"bad_transfers\"] / (table[\"good_transfers\"] + table[\"bad_transfers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fdp_flash(o_peaks_path, c_peaks_path, censored_psm_path, human_file_pattern = \"_1x02nguL_\",\n",
    "                   foreign_species = 'Saccharomyces cerevisiae', q_value = 0.05, rt_delta = 0.5):\n",
    "\n",
    "    peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
    "    peaks = peaks.loc[peaks[\"File Name\"].str.contains(human_file_pattern)]\n",
    "\n",
    "    msms_detected_yeast_peaks = peaks.loc[(peaks[\"Peak Detection Type\"] == \"MSMS\") &\n",
    "                           (peaks[\"Organism\"].str.contains(foreign_species))]\n",
    "    msms_detected_yeast_peaks.drop_duplicates(subset = [\"Full Sequence\"], keep = 'first', inplace = True)\n",
    "    msms_yeast_seqs = msms_detected_yeast_peaks[\"Full Sequence\"].tolist()\n",
    "\n",
    "    msms_peaks = peaks.loc[(peaks[\"Peak Detection Type\"] == \"MSMS\") &\n",
    "                           (peaks[\"Decoy Peptide\"] == False) &\n",
    "                           ((peaks[\"Organism\"].str.contains(foreign_species)) | (peaks[\"Organism\"].str.contains('Homo sapiens')) | (peaks[\"Organism\"].str.contains('Arabidopsis')))]\n",
    "    msms_count = msms_peaks.shape[0]\n",
    "\n",
    "    peaks = peaks.loc[(peaks[\"Peak Detection Type\"] == \"MBR\") & (peaks[\"PIP Q-Value\"] < q_value) & (peaks[\"Decoy Peptide\"] == False)]\n",
    "\n",
    "    peaks = peaks.loc[(peaks[\"Random RT\"] == False) & (peaks[\"Decoy Peptide\"] == False)]\n",
    "\n",
    "    human_peaks = peaks.loc[peaks[\"Organism\"].str.contains('Homo sapiens')]\n",
    "    # Our entrapment database has a bunch of scrambled sequences appended to the end of the DB, which is why we're checking for them\n",
    "    entrapment_peaks = human_peaks.loc[human_peaks[\"Full Sequence\"].isin(entrapment_seqs_set)]\n",
    "    human_peaks = human_peaks.loc[~human_peaks[\"Base Sequence\"].isin(entrapment_seqs_set)]\n",
    "    \n",
    "    human_count = human_peaks.shape[0]\n",
    "    arabida_count = entrapment_peaks.shape[0]\n",
    "\n",
    "    yeast_peaks = peaks.loc[peaks[\"Organism\"].str.contains(foreign_species)]\n",
    "    yeast_peaks = yeast_peaks.loc[~yeast_peaks[\"Organism\"].str.contains('Homo sapiens')]\n",
    "    yeast_count = yeast_peaks.shape[0]\n",
    "    \n",
    "    msms_yeast_count = sum(yeast_peaks[\"Full Sequence\"].isin(msms_yeast_seqs))\n",
    "    yeast_count = yeast_count - msms_yeast_count\n",
    "\n",
    "    score_threshold = peaks[\"PIP PEP\"].max()\n",
    "\n",
    "    # calculate the error rate for (presumably) native human transfers\n",
    "    nper_results = get_native_peak_error_rate( \n",
    "                            o_peaks_path = o_peaks_path,\n",
    "                            c_peaks_path = c_peaks_path,\n",
    "                            censored_psm_path = censored_psm_path,\n",
    "                            q_value_threshold = q_value,\n",
    "                            score_threshold = score_threshold,\n",
    "                            rt_delta = rt_delta)\n",
    "    \n",
    "\n",
    "    scaled_arabida = arabida_count * scaling_factor\n",
    "    scaled_nper = human_count * nper_results[\"error_rate\"]\n",
    "\n",
    "    total = human_count + yeast_count + arabida_count\n",
    "    total = max(1, total)\n",
    "\n",
    "    fper = 100 * yeast_count / total\n",
    "    nper = 100 * scaled_nper / total\n",
    "    fder = 100 * scaled_arabida / total\n",
    "\n",
    "    false_discovery_proportion = fper + nper + fder\n",
    "\n",
    "    results = dict(\n",
    "        {\n",
    "            \"human\": human_count,\n",
    "            \"foreign\": yeast_count,\n",
    "            \"arabida\": arabida_count,\n",
    "            \"total\": total,\n",
    "            \"msms_count\" : msms_count,\n",
    "            \"scaled_arabida\": scaled_arabida,\n",
    "            \"scaled_nper\": scaled_nper,\n",
    "            \"sensitivity\": nper_results[\"sensitivity\"],\n",
    "            \"fper\": fper,\n",
    "            \"nper\": nper,\n",
    "            \"fder\": fder,\n",
    "            \"false_discovery_proportion\": false_discovery_proportion\n",
    "        }\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Native Peak Error Rate functions\n",
    "def check_overlap_time(table, rt_delta = 0.25):\n",
    "    try:\n",
    "        pip_apex = float(table[\"Peak RT Apex_y\"])\n",
    "        ms_apex = float(table[\"Peak RT Apex_x\"])\n",
    "    except:\n",
    "        return -1\n",
    "    if(abs(pip_apex-ms_apex) < rt_delta):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def calculateErrorRate(table):\n",
    "    return table[\"bad_transfers\"] / (table[\"good_transfers\"] + table[\"bad_transfers\"])\n",
    "\n",
    "def get_native_peak_error_rate(o_peaks_path, c_peaks_path, censored_psm_path, q_value_threshold, score_threshold=10, rt_delta = 0.25):\n",
    "    # Read in the list of peptides that were censored\n",
    "    censored_psms = pd.read_csv(censored_psm_path, sep = '\\t')\n",
    "    # Select the ones that were quantified in the initial FlashLFQ analysis\n",
    "    original_peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
    "    original_peaks = original_peaks[original_peaks[\"Peak RT Apex\"] != \"-\"]\n",
    "    \n",
    "    censored_peaks = pd.merge(censored_psms, original_peaks, how = \"inner\", left_on=[\"File Name\", \"Full Sequence\"], right_on=[\"File Name\", \"Full Sequence\"])\n",
    "    censored_peaks = censored_peaks[[\"File Name\", \"Full Sequence\", \"Peak RT Start\", \"Peak RT Apex\", \"Peak RT End\", \"Peak Charge\", \"Peak intensity\"]]\n",
    "\n",
    "    # This will allow for comparison later, as all the new peaks were take from files named in this way\n",
    "    censored_peaks[\"File Name\"] = censored_peaks[\"File Name\"].astype(str) + \"-censored\" \n",
    "\n",
    "    # Merge the old and new results\n",
    "    new_peaks = pd.read_csv(c_peaks_path, sep = '\\t')\n",
    "    new_peaks = new_peaks.loc[(new_peaks[\"Peak Detection Type\"] == \"MBR\") & (new_peaks[\"Random RT\"] == False) & (new_peaks[\"Decoy Peptide\"] == False)]\n",
    "    new_peaks = new_peaks.loc[(new_peaks[\"PIP Q-Value\"] < q_value_threshold)]\n",
    "    #new_peaks = new_peaks.loc[(new_peaks[\"MBR Score\"] > score_threshold)]\n",
    "    new_peaks = new_peaks[[\"File Name\", \"Full Sequence\", \"Peak RT Start\", \"Peak RT Apex\", \"Peak RT End\", \"Peak Charge\",  \"Peak intensity\", \"PIP PEP\", 'PIP Q-Value']]\n",
    "    peak_join = pd.merge(censored_peaks, new_peaks, how = \"inner\", left_on=[\"File Name\", \"Full Sequence\"], right_on=[\"File Name\", \"Full Sequence\"])\n",
    "\n",
    "    peak_join[\"Agreement\"] = peak_join.apply(lambda x: check_overlap_time(x, rt_delta), axis = 1)\n",
    "    peak_join.sort_values(by = \"Agreement\", ascending=False, inplace=True)\n",
    "\n",
    "    #compare the old and new results (here, 1 means the match, 0 means they dont)\n",
    "    peak_join.drop_duplicates(subset = [\"File Name\", \"Full Sequence\"], keep = 'first', inplace=True)\n",
    "    censored_peaks.drop_duplicates(subset = [\"File Name\", \"Full Sequence\"], keep = 'first', inplace=True)\n",
    "    sensitivity = peak_join.shape[0] / censored_peaks.shape[0]\n",
    "\n",
    "\n",
    "    if(peak_join.shape[0] == 0):\n",
    "        return dict({\n",
    "            \"sensitivity\": 0,\n",
    "            \"error_rate\": 0} )\n",
    "\n",
    "    peak_join.sort_values(by = 'PIP Q-Value', ascending=True, inplace=True)\n",
    "    peak_join[\"good_transfers\"] = (peak_join[\"Agreement\"] == 1).cumsum()\n",
    "    peak_join[\"bad_transfers\"] = (peak_join[\"Agreement\"] == 0).cumsum()\n",
    "    peak_join[\"error_rate\"] = peak_join.apply(calculateErrorRate, axis = 1)\n",
    "\n",
    "    results = dict(\n",
    "        {\n",
    "            \"sensitivity\": sensitivity,\n",
    "            \"error_rate\": peak_join[\"error_rate\"].iloc[-1]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fdp_fragger(o_folder = r\"D:\\GygiTwoProteome_PXD014415\\IonQuant1Percent\",\n",
    "                      c_folder= r\"D:\\GygiTwoProteome_PXD014415\\IonQuant1Percent_censored\",\n",
    "                      censored_psm_path = r\"D:\\GygiTwoProteome_PXD014415\\CensoredDataFiles_fragger\\CensoredPsms.tsv\",\n",
    "                      foreign_species = \"YEAST\",\n",
    "                      human_file_pattern = \"_human_90min_\",\n",
    "                      rt_diff_threshold = 0.5):\n",
    "        \n",
    "        rt_diff_threshold = rt_diff_threshold * 60 # Convert to seconds, which is how iq stores RT\n",
    "\n",
    "        human_rep_indices = get_indices(o_folder, human_file_pattern)\n",
    "        human_rep_indices_censored = get_indices(c_folder, human_file_pattern)\n",
    "        \n",
    "        ion_count = count_ions_by_species(o_folder + r\"\\combined_modified_peptide.tsv\", match_indices = human_rep_indices, foreign_species = foreign_species)\n",
    "        nper_results = analyze_nper(o_folder = o_folder, c_folder = c_folder, censored_psm_path = censored_psm_path, \n",
    "                                         human_rep_indices = human_rep_indices, human_rep_indices_censored = human_rep_indices_censored,\n",
    "                                         rt_diff_threshold = rt_diff_threshold)\n",
    "        \n",
    "        scaled_arabida = ion_count[\"arabida\"] * scaling_factor\n",
    "        scaled_nper = ion_count[\"human\"] * nper_results[\"specificity\"]\n",
    "\n",
    "        ion_count[\"scaled_arabida\"] = scaled_arabida\n",
    "        ion_count[\"scaled_nper\"] = scaled_nper\n",
    "        ion_count[\"specificity\"] = nper_results[\"specificity\"]\n",
    "        ion_count[\"sensitivity\"] = nper_results[\"sensitivity\"]\n",
    "        ion_count[\"nper_pct_diff\"] = nper_results[\"intensity_diff\"]\n",
    "\n",
    "        ion_count[\"fper\"] = 100 * ion_count[\"foreign\"]  / ion_count[\"total\"]\n",
    "        ion_count[\"nper\"] = 100 * ion_count[\"scaled_nper\"]  / ion_count[\"total\"]\n",
    "        ion_count[\"fder\"] = 100 * ion_count[\"scaled_arabida\"]  / ion_count[\"total\"]\n",
    "        ion_count[\"false_discovery_proportion\"] = ion_count[\"fper\"] + ion_count[\"nper\"] + ion_count[\"fder\"]\n",
    "\n",
    "        return ion_count\n",
    "    \n",
    "def get_indices(folder_path, pattern = \"_human_90min_\"):\n",
    "    exp_file_path = folder_path + r\"\\experiment_annotation.tsv\"\n",
    "    exp_file = pd.read_csv(exp_file_path, sep = '\\t')\n",
    "    human_indices = exp_file[exp_file[\"file\"].str.contains(pattern)].index\n",
    "    return human_indices\n",
    "\n",
    "def analyze_nper(o_folder,\n",
    "                      c_folder,\n",
    "                      censored_psm_path,\n",
    "                      human_rep_indices,\n",
    "                      human_rep_indices_censored = None,\n",
    "                      rt_diff_threshold = 30):\n",
    "    \n",
    "    if(not any(human_rep_indices)):\n",
    "        human_rep_indices_censored = human_rep_indices\n",
    "\n",
    "    o_annotation_path = o_folder + r\"\\experiment_annotation.tsv\"\n",
    "    annotation_file = pd.read_csv(o_annotation_path, sep = '\\t')\n",
    "    file_dict_o = dict(zip(annotation_file.file, annotation_file.sample_name))\n",
    "    original_file_dict = dict()\n",
    "    for old_key in file_dict_o.keys():\n",
    "        new_key = old_key.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        original_file_dict[new_key] = file_dict_o[old_key]\n",
    "\n",
    "    c_annotation_path = c_folder + r\"\\experiment_annotation.tsv\"\n",
    "    annotation_file = pd.read_csv(c_annotation_path, sep = '\\t')\n",
    "    file_dict_c = dict(zip(annotation_file.file, annotation_file.sample_name))\n",
    "    censored_file_dict = dict()\n",
    "    for old_key in file_dict_c.keys():\n",
    "        new_key = old_key.replace(\"-censored\", \"\").split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        censored_file_dict[new_key] = file_dict_c[old_key]\n",
    "\n",
    "    # Read in the censored psms\n",
    "    censored_psms = pd.read_csv(censored_psm_path, sep = '\\t')\n",
    "    censored_psms[\"File Name\"] = censored_psms[\"Spectrum File\"].apply(lambda x: x.replace(\"-censored\", \"\").replace(\"interact-\", \"\").split(\"\\\\\")[-1].split(\".\")[0])\n",
    "    # The mods got screwed up during writing the psms, so we fix that here\n",
    "    censored_psms[\"Modified Peptide\"] = censored_psms.apply(lambda x: x[\"Modified Peptide\"].replace(\"43\", \"42.0106\"), axis = 1)\n",
    "    censored_psms[\"Modified Peptide\"] = censored_psms.apply(lambda x: x[\"Modified Peptide\"].replace(\"147\", \"15.9949\"), axis = 1)\n",
    "    censored_psms[\"Modified Peptide\"] = censored_psms.apply(lambda x: x[\"Modified Peptide\"].replace(\"C\", \"C[57.0215]\"), axis = 1)\n",
    "\n",
    "    # Read in the original ions\n",
    "    o_ion_path = o_folder + r\"\\combined_ion.tsv\"\n",
    "    original_ions = pd.read_csv(o_ion_path, sep = '\\t')\n",
    "\n",
    "    info_cols = original_ions.columns[[0, 1, 7,8,11,12,13,14,15,16, 17]].to_list()\n",
    "\n",
    "    match_cols = [col for col in original_ions.columns if \"Match Type\" in col]\n",
    "    intensity_cols = [col for col in original_ions.columns if \"Intensity\" in col]\n",
    "    rt_cols = [col for col in original_ions.columns if \"Apex Retention Time\" in col]\n",
    "\n",
    "    match_cols = [match_cols[i] for i in human_rep_indices]\n",
    "    rt_cols = [rt_cols[i] for i in human_rep_indices]\n",
    "    intensity_cols = [intensity_cols[i] for i in human_rep_indices]\n",
    "\n",
    "    original_ions = original_ions[info_cols + match_cols + rt_cols + intensity_cols]\n",
    "\n",
    "    ion_melt = pd.melt(original_ions, id_vars = info_cols + match_cols + intensity_cols, value_vars=rt_cols, var_name=\"RT Column\", value_name=\"RT\")\n",
    "    ion_melt[\"Match Type\"] = ion_melt.apply(get_match_type, axis = 1)\n",
    "    ion_melt[\"Intensity\"] = ion_melt.apply(get_intensity, axis = 1)\n",
    "    ion_melt.drop(match_cols + intensity_cols, axis = 1, inplace = True)\n",
    "    ion_melt = ion_melt.loc[ion_melt[\"Match Type\"] == \"MS/MS\"]\n",
    "\n",
    "    original_file_rev_dict = dict((v, k) for k, v in original_file_dict.items())\n",
    "    ion_melt[\"File Name\"] = ion_melt.apply(lambda x: original_file_rev_dict[x[\"RT Column\"].split(\" \")[0]], axis = 1)\n",
    "    o_ion_merge = pd.merge(left = ion_melt, right=censored_psms[[\"File Name\", \"Modified Peptide\"]],\n",
    "                            how = \"inner\", left_on = [\"File Name\", \"Modified Sequence\"], right_on = [\"File Name\", \"Modified Peptide\"])\n",
    "    o_ion_merge = o_ion_merge.sort_values(\"Intensity\", ascending=False).groupby([\"Modified Sequence\", \"File Name\"], as_index = False).first() # Keep only the highest intensity charge state\n",
    "\n",
    "\n",
    "    #Read in the ions derived from the censored data\n",
    "    # melt it to have one row per peak (need to group rt, intensity, etc.)\n",
    "    c_ion_path = c_folder + r\"\\combined_ion.tsv\"\n",
    "    censored_ions = pd.read_csv(c_ion_path, sep = '\\t')\n",
    "    info_cols = censored_ions.columns[[0, 1, 7,8,11,12,13,14,15,16, 17]].to_list()\n",
    "\n",
    "    match_cols = [col for col in censored_ions.columns if \"Match Type\" in col]\n",
    "    intensity_cols = [col for col in censored_ions.columns if \"Intensity\" in col]\n",
    "    rt_cols = [col for col in censored_ions.columns if \"Apex Retention Time\" in col]\n",
    "\n",
    "    match_cols = [match_cols[i] for i in human_rep_indices_censored]\n",
    "    rt_cols = [rt_cols[i] for i in human_rep_indices_censored]\n",
    "    intensity_cols = [intensity_cols[i] for i in human_rep_indices_censored]\n",
    "\n",
    "    censored_ions = censored_ions[info_cols + match_cols + rt_cols + intensity_cols]\n",
    "\n",
    "    c_ion_melt = pd.melt(censored_ions, id_vars = info_cols + match_cols + intensity_cols, value_vars=rt_cols, var_name=\"RT Column\", value_name=\"RT\")\n",
    "    c_ion_melt[\"Match Type\"] = c_ion_melt.apply(get_match_type, axis = 1)\n",
    "    c_ion_melt[\"Intensity\"] = c_ion_melt.apply(get_intensity, axis = 1)\n",
    "    c_ion_melt.drop(match_cols + intensity_cols, axis = 1, inplace = True)\n",
    "\n",
    "    censored_file_rev_dict = dict((v, k) for k, v in censored_file_dict.items())\n",
    "    c_ion_melt[\"File Name\"] = c_ion_melt.apply(lambda x: censored_file_rev_dict[x[\"RT Column\"].split(\" \")[0]], axis = 1)\n",
    "    c_ion_melt = c_ion_melt.loc[c_ion_melt[\"Match Type\"] == \"MBR\"]\n",
    "    c_ion_merge = pd.merge(left = c_ion_melt, right=censored_psms[[\"File Name\", \"Modified Peptide\"]],\n",
    "                            how = \"right\", left_on = [\"File Name\", \"Modified Sequence\"], right_on = [\"File Name\", \"Modified Peptide\"])\n",
    "    c_ion_merge = c_ion_merge.sort_values(\"Intensity\", ascending=False).groupby([\"Modified Sequence\", \"File Name\"], as_index = False).first() # Keep only the highest intensity charge state\n",
    "\n",
    "    # Calculate the sensitivity (number of MBR ions / number of ions detected w/ MSMS)\n",
    "    ion_comp = pd.merge(o_ion_merge, c_ion_merge, on = [\"Modified Peptide\", \"File Name\"], suffixes = (\"_o\", \"_c\"), how = \"inner\")\n",
    "    ion_comp = ion_comp[ion_comp[\"RT_o\"].notna() & ion_comp[\"RT_c\"].notna()]\n",
    "    ion_comp[\"RT_diff\"] = abs(ion_comp[\"RT_o\"] - ion_comp[\"RT_c\"])\n",
    "    ion_comp.sort_values(\"RT_diff\", ascending=True, inplace=True)\n",
    "    ion_comp = ion_comp.drop_duplicates(subset = [\"Modified Peptide\", \"File Name\"], keep = 'first')\n",
    "    specificity = sum(ion_comp[\"RT_diff\"] > rt_diff_threshold) / ion_comp.shape[0]\n",
    "\n",
    "    ion_diffs = ion_comp.loc[ion_comp[\"RT_diff\"] > rt_diff_threshold]\n",
    "    pct_diffs = ion_diffs.apply(lambda x: 100 * abs(x[\"Intensity_o\"] - x[\"Intensity_c\"]) /\n",
    "                                             ((x[\"Intensity_o\"] + x[\"Intensity_c\"]) / 2.0), axis = 1)\n",
    "    \n",
    "\n",
    "    o_ion_merge.drop_duplicates(subset = [\"Modified Peptide\", \"File Name\"], inplace = True)\n",
    "    c_ion_merge.drop_duplicates(subset = [\"Modified Peptide\", \"File Name\"], inplace = True)\n",
    "    number_of_ions_original = o_ion_merge.shape[0] - o_ion_merge[\"RT\"].isna().sum()\n",
    "    number_of_ions_censored = c_ion_merge.shape[0] - c_ion_merge[\"RT\"].isna().sum()\n",
    "    sensitivity = number_of_ions_censored / number_of_ions_original\n",
    "\n",
    "    results = dict(sensitivity = sensitivity, specificity = specificity, intensity_diff = pct_diffs.mean())\n",
    "    return results\n",
    "\n",
    "\n",
    "# combined_ion parsing functions\n",
    "def get_match_type(row):\n",
    "    return(row[row[\"RT Column\"].split(\" \")[0] + \" Match Type\"])\n",
    "\n",
    "def get_intensity(row):\n",
    "    return(row[row[\"RT Column\"].split(\" \")[0] + \" Intensity\"])\n",
    "\n",
    "def count_ions_by_species(path_to_combined_ion, match_indices = [0, 1, 2, 3, 4, 5, 6 ], foreign_species = \"YEAST\"):\n",
    "    entrapment_species = \"_ENT\"\n",
    "\n",
    "    # Read in combined ions\n",
    "    ions = pd.read_csv(path_to_combined_ion, sep = '\\t')\n",
    "    # Keep informative columns (species, peptide, etc.) and \"... Match Type\" columns\n",
    "    match_cols = [col for col in ions.columns if \"Match Type\" in col]\n",
    "    # WARNING - This line is experiment dependent and should be changed based on the samples you wish to analyze\n",
    "    match_cols = [match_cols[i] for i in match_indices] #Remove the two mixed proteome samples \n",
    "    info_cols = ions.columns[[0, 1, 7,8,11,12,13,14,15,16, 17]].to_list()\n",
    "    ions = ions[info_cols + match_cols]\n",
    "    # us melt to create one row per sample match type\n",
    "    ion_mbr = ions.melt(info_cols)\n",
    "\n",
    "    foreign_msms = ion_mbr.loc[(ion_mbr[\"Entry Name\"].str.contains(foreign_species)) & (ion_mbr[\"value\"] == \"MS/MS\")]\n",
    "    foreign_msms_seqs = set(foreign_msms[\"Modified Sequence\"].tolist())\n",
    "    \n",
    "    ion_msms = ion_mbr.loc[ion_mbr.value == \"MS/MS\"]\n",
    "    ion_msms = ion_msms.loc[(ion_msms[\"Entry Name\"].str.contains(\"HUMAN\")) | (ion_msms[\"Entry Name\"].str.contains(foreign_species)) | (ion_msms[\"Entry Name\"].str.contains(entrapment_species))]\n",
    "    msms_count = ion_msms.shape[0]\n",
    "\n",
    "    # keep only the MBR match types\n",
    "    ion_mbr = ion_mbr.loc[ion_mbr.value == \"MBR\"]\n",
    "\n",
    "    ion_mbr.drop_duplicates(subset = [\"Modified Sequence\", \"variable\"], inplace = True)\n",
    "\n",
    "    # Count the number of ions from each species\n",
    "    human_ions = ion_mbr.loc[ion_mbr[\"Entry Name\"].str.contains(\"HUMAN\")]\n",
    "    real_human_ions = human_ions.loc[~human_ions[\"Peptide Sequence\"].isin(entrapment_seqs_set)]\n",
    "    entrapment_ions = human_ions.loc[human_ions[\"Peptide Sequence\"].isin(entrapment_seqs_set)]\n",
    "    human_ion_count = real_human_ions.shape[0]\n",
    "    arath_ion_count = entrapment_ions.shape[0]\n",
    "\n",
    "    foreign_ions = ion_mbr.loc[ion_mbr[\"Entry Name\"].str.contains(foreign_species)]\n",
    "    foreign_ions[\"Mapped Proteins\"] = foreign_ions[\"Mapped Proteins\"].fillna('')\n",
    "    foreign_ions = foreign_ions.loc[~foreign_ions[\"Mapped Proteins\"].str.contains(\"HUMAN\")]\n",
    "    foreign_ion_count = foreign_ions.shape[0]\n",
    "\n",
    "    foreign_double_count = sum(foreign_ions[\"Modified Sequence\"].isin(foreign_msms_seqs))\n",
    "    foreign_ion_count = foreign_ion_count - foreign_double_count\n",
    "\n",
    "\n",
    "\n",
    "    count_dict = dict(\n",
    "        {\n",
    "            \"human\" : human_ion_count,\n",
    "            \"foreign\" : foreign_ion_count,\n",
    "            \"arabida\" : arath_ion_count,\n",
    "            \"total\" : human_ion_count + foreign_ion_count + arath_ion_count,\n",
    "            \"msms_count\" : msms_count,\n",
    "            \"mbr_count\" : ion_mbr.shape[0]\n",
    "        })\n",
    "    return(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fdp_maxquant(path, foreign_species = \"Yeast\", human_file_pattern = \"_human_90min_\"):\n",
    "    \n",
    "    ion_count = count_ions_by_species_mq(path, foreign_species, human_file_pattern)\n",
    "\n",
    "    scaled_arabida = ion_count[\"arabida\"] * scaling_factor\n",
    "        \n",
    "    ion_count[\"scaled_arabida\"] = scaled_arabida\n",
    "\n",
    "    ion_count[\"fper\"] = 100 * ion_count[\"foreign\"]  / ion_count[\"total\"]\n",
    "    ion_count[\"nper\"] = 0 # MaxQuant doesn't support mzML files, so no censored analysis was performed, and the number of native peak errors couldn't be evaluated\n",
    "    ion_count[\"fder\"] = 100 * ion_count[\"scaled_arabida\"]  / ion_count[\"total\"]\n",
    "    ion_count[\"false_discovery_proportion\"] = ion_count[\"fper\"] + ion_count[\"nper\"] + ion_count[\"fder\"]\n",
    "\n",
    "    return ion_count\n",
    "\n",
    "def count_ions_by_species_mq(evidence_path = r\"D:\\Gygi_TwoProteomeData\\combined_MaxQuant_Gygi\\txt\\evidence.txt\", foreign_species = \"Yeast\",\n",
    "                             human_file_pattern = \"_human_90min_\"):\n",
    "    \n",
    "    evidence = pd.read_csv(evidence_path, sep = '\\t')\n",
    "    evidence = evidence.loc[(evidence[\"Reverse\"] != \"+\") & (evidence[\"Raw file\"].str.contains(human_file_pattern))]\n",
    "    evidence[\"Proteins\"] = evidence[\"Proteins\"].astype(str)\n",
    "    evidence[\"Organism\"] = evidence.apply(lambda x: ';'.join([get_species(protein) for protein in x['Proteins'].split(';')]), axis = 1)\n",
    "    \n",
    "    msms_foreign = evidence.loc[(evidence[\"MS/MS count\"] > 0) & (evidence[\"Organism\"].str.contains(foreign_species))]\n",
    "    msms_foreign_seq = set(msms_foreign[\"Modified sequence\"].tolist())\n",
    "\n",
    "    pip = evidence.loc[evidence[\"Match score\"].isna() == False]\n",
    "    pip = pip.loc[pip[\"Raw file\"].str.contains(human_file_pattern)]\n",
    "\n",
    "    human_ions = pip.loc[pip[\"Organism\"].str.contains(\"Human\")]\n",
    "    human_ion_real = human_ions.loc[~human_ions[\"Sequence\"].isin(entrapment_seqs_set)]  \n",
    "    entrapment_ions = human_ions.loc[human_ions[\"Sequence\"].isin(entrapment_seqs_set)]  \n",
    "    human_ion_count = human_ion_real.shape[0]\n",
    "    arath_ion_count = entrapment_ions.shape[0]\n",
    "\n",
    "    foreign_ions = pip.loc[pip[\"Organism\"].str.contains(foreign_species)]\n",
    "    foreign_ions = foreign_ions.loc[~foreign_ions[\"Organism\"].str.contains(\"Human\")]\n",
    "    foreign_ion_count = foreign_ions.shape[0]\n",
    "\n",
    "    foreign_ion_double_count = sum(foreign_ions[\"Modified sequence\"].isin(msms_foreign_seq))\n",
    "    foreign_ion_count = foreign_ion_count - foreign_ion_double_count\n",
    "\n",
    "    count_dict = dict(\n",
    "        {\n",
    "            \"human\" : human_ion_count,\n",
    "            \"foreign\" : foreign_ion_count,\n",
    "            \"arabida\" : arath_ion_count,\n",
    "            \"total\" : sum([human_ion_count, foreign_ion_count, arath_ion_count])\n",
    "        })\n",
    "    return count_dict\n",
    "\n",
    "def get_species(accession):\n",
    "    species = accession_dict.get(accession, 'Other')\n",
    "    return species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gygi RT Threshold:  0.9\n",
      "Kelly RT Threshold:  0.4\n",
      "Inhouse RT Threshold:  0.6\n"
     ]
    }
   ],
   "source": [
    "# RT thresholds for native peak error calculations\n",
    "\n",
    "gygi_rt = 90 * 0.01\n",
    "inhouse_rt = 60 * 0.01\n",
    "kelly_rt = 40 * 0.01\n",
    "\n",
    "print(\"Gygi RT Threshold: \", gygi_rt)\n",
    "print(\"Kelly RT Threshold: \", kelly_rt)\n",
    "print(\"Inhouse RT Threshold: \", inhouse_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_33628\\3474247082.py:5: DtypeWarning: Columns (9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_33628\\3474247082.py:77: DtypeWarning: Columns (9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_peaks = pd.read_csv(old_peak_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_33628\\3474247082.py:85: DtypeWarning: Columns (9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_peaks = pd.read_csv(new_peak_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_33628\\3474247082.py:5: DtypeWarning: Columns (9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n"
     ]
    }
   ],
   "source": [
    "gygi_path = data_path + \"LimDataset\\\\\"\n",
    "inhouse_path = data_path + \"EcoliDataset\\\\\"\n",
    "kelly_path = data_path + \"SingleCellDataset\\\\\"\n",
    "\n",
    "gygi_flashv1 = get_fdp_old_flash(o_peaks_path =  gygi_path + \"Lim_QuantResults-FlashLFQv1\\FlashLFQ_CurRel_PepQ_ConcatenatedDb\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = gygi_path + \"Lim_QuantResults-FlashLFQv1\\CensoredData_FlashLFQ_CurRel_PepQ_ConcatenatedDb\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = gygi_path + \"CensoredFiles-MetaMorpheus\\CensoredPsms.psmtsv\",\n",
    "                          human_file_pattern=\"human_90\", foreign_species='Yeast', rt_delta=gygi_rt)\n",
    "\n",
    "inhouse_flashv1 = get_fdp_old_flash(o_peaks_path =  inhouse_path + \"Ecoli_QuantResults-FlashLFQv1\\\\Human_FlashLFQ_CurRel_PepQ_NewDb\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = inhouse_path + \"Ecoli_QuantResults-FlashLFQv1\\\\CensoredHuman_FlashLFQ_CurRel_PepQ_NewDb\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = inhouse_path + \"Ecoli_CensoredFiles-MetaMorpheus\\\\CensoredPsms.psmtsv\",\n",
    "                          human_file_pattern=\"Human_C18\", foreign_species='Ecoli', rt_delta=inhouse_rt)\n",
    "\n",
    "kelly_flashv1= get_fdp_old_flash(o_peaks_path =  kelly_path + \"SingleCell_QuantResults-FlashLFQv1\\\\FlashLFQ_CurRel_PepQ_ConcatenatedDb\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = kelly_path + \"SingleCell_QuantResults-FlashLFQv1\\\\CensoredData_FlashLFQ_CurRel_PepQ_ConcatenatedDb\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = kelly_path + \"CensoredFiles-MetaMorpheus\\\\CensoredPsms.psmtsv\",\n",
    "                          human_file_pattern=\"_1x02nguL_\", foreign_species='Yeast', rt_delta=kelly_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "kelly_censored_psms = kelly_path + \"CensoredFiles-MetaMorpheus\\\\CensoredPsms.psmtsv\"\n",
    "\n",
    "kelly_dd_1 = get_fdp_flash(o_peaks_path =  kelly_path + \"SingleCell_QuantResults-FlashLFQ_PIP-ECHO\\\\FlashLFQ_7772_DonorPepQ_02\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = kelly_path + \"SingleCell_QuantResults-FlashLFQ_PIP-ECHO\\\\CensoredData_FlashLFQ_7772_DonorPepQ_02\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = kelly_censored_psms,\n",
    "                          human_file_pattern=\"_1x02nguL_\", foreign_species='Saccharomyces cerevisiae', q_value=0.01, rt_delta=kelly_rt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:4: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:97: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:107: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_peaks = pd.read_csv(c_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:4: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:97: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:107: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_peaks = pd.read_csv(c_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:4: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:97: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:107: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_peaks = pd.read_csv(c_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:4: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:97: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:107: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_peaks = pd.read_csv(c_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:4: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:97: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:107: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_peaks = pd.read_csv(c_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:4: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:97: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_peaks = pd.read_csv(o_peaks_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\1899044835.py:107: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_peaks = pd.read_csv(c_peaks_path, sep = '\\t')\n"
     ]
    }
   ],
   "source": [
    "# Current FlashLFQ\n",
    "gygi_censored_psms = gygi_path + \"CensoredFiles-MetaMorpheus\\\\CensoredPsms.psmtsv\"\n",
    "\n",
    "gygi_dd_1 = get_fdp_flash(o_peaks_path =  gygi_path + \"Lim_QuantResults-FlashLFQ_PIP_ECHO\\\\FlashLFQ_7772_DonorPepQ_02\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = gygi_path + \"Lim_QuantResults-FlashLFQ_PIP_ECHO\\\\CensoredData_FlashLFQ_7772_DonorPepQ_02\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = gygi_censored_psms,\n",
    "                          human_file_pattern=\"human_90\", foreign_species='Saccharomyces cerevisiae', q_value=0.01, rt_delta=gygi_rt)\n",
    "\n",
    "gygi_dd_2p5 = get_fdp_flash(o_peaks_path =  gygi_path + \"Lim_QuantResults-FlashLFQ_PIP_ECHO\\\\FlashLFQ_7772_DonorPepQ_05\\QuantifiedPeaks.tsv\",\n",
    "                            c_peaks_path = gygi_path + \"Lim_QuantResults-FlashLFQ_PIP_ECHO\\\\CensoredData_FlashLFQ_7772_DonorPepQ_05\\QuantifiedPeaks.tsv\",\n",
    "                            censored_psm_path = gygi_censored_psms,\n",
    "                            human_file_pattern=\"human_90\", foreign_species='Saccharomyces cerevisiae', q_value=0.025, rt_delta=gygi_rt)\n",
    "\n",
    "gygi_dd_5 = get_fdp_flash(o_peaks_path =  gygi_path + \"Lim_QuantResults-FlashLFQ_PIP_ECHO\\\\FlashLFQ_7772_DonorPepQ_1\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = gygi_path + \"Lim_QuantResults-FlashLFQ_PIP_ECHO\\\\CensoredData_FlashLFQ_7772_DonorPepQ_1\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = gygi_censored_psms,\n",
    "                          human_file_pattern=\"human_90\", foreign_species='Saccharomyces cerevisiae', q_value=0.05, rt_delta=gygi_rt)\n",
    "\n",
    "inhouse_censored_psms = inhouse_path + \"Ecoli_CensoredFiles-MetaMorpheus\\\\CensoredPsms.psmtsv\"\n",
    "\n",
    "inhouse_dd_1 = get_fdp_flash(o_peaks_path =  inhouse_path + \"Ecoli_QuantResults-FlashLFQ_PIP-ECHO\\\\Human_FlashLFQ_7772_DonorPepQ_02\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = inhouse_path + \"Ecoli_QuantResults-FlashLFQ_PIP-ECHO\\\\CensoredHuman_FlashLFQ_7772_DonorPepQ_02\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = inhouse_censored_psms,\n",
    "                          human_file_pattern=\"Human_C18\", foreign_species='Escherichia coli', q_value=0.01, rt_delta=inhouse_rt)\n",
    "\n",
    "inhouse_dd_2p5 = get_fdp_flash(o_peaks_path =  inhouse_path + \"Ecoli_QuantResults-FlashLFQ_PIP-ECHO\\\\Human_FlashLFQ_7772_DonorPepQ_05\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = inhouse_path + \"Ecoli_QuantResults-FlashLFQ_PIP-ECHO\\\\CensoredHuman_FlashLFQ_7772_DonorPepQ_05\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = inhouse_censored_psms,\n",
    "                          human_file_pattern=\"Human_C18\", foreign_species='Escherichia coli', q_value=0.025, rt_delta=inhouse_rt)\n",
    "\n",
    "inhouse_dd_5 = get_fdp_flash(o_peaks_path =  inhouse_path + \"Ecoli_QuantResults-FlashLFQ_PIP-ECHO\\\\Human_FlashLFQ_7772_DonorPepQ_1\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = inhouse_path + \"Ecoli_QuantResults-FlashLFQ_PIP-ECHO\\\\CensoredHuman_FlashLFQ_7772_DonorPepQ_1\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = inhouse_censored_psms,\n",
    "                          human_file_pattern=\"Human_C18\", foreign_species='Escherichia coli', q_value=0.05, rt_delta=inhouse_rt)\n",
    "\n",
    "kelly_censored_psms = kelly_path + \"CensoredFiles-MetaMorpheus\\\\CensoredPsms.psmtsv\"\n",
    "\n",
    "kelly_dd_1 = get_fdp_flash(o_peaks_path =  kelly_path + \"SingleCell_QuantResults-FlashLFQ_PIP-ECHO\\\\FlashLFQ_7772_DonorPepQ_02\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = kelly_path + \"SingleCell_QuantResults-FlashLFQ_PIP-ECHO\\\\CensoredData_FlashLFQ_7772_DonorPepQ_02\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = kelly_censored_psms,\n",
    "                          human_file_pattern=\"_1x02nguL_\", foreign_species='Saccharomyces cerevisiae', q_value=0.01, rt_delta=kelly_rt)\n",
    "\n",
    "kelly_dd_2p5 = get_fdp_flash(o_peaks_path =  kelly_path + \"SingleCell_QuantResults-FlashLFQ_PIP-ECHO\\\\FlashLFQ_7772_DonorPepQ_05\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = kelly_path + \"SingleCell_QuantResults-FlashLFQ_PIP-ECHO\\\\CensoredData_FlashLFQ_7772_DonorPepQ_05\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = kelly_censored_psms,\n",
    "                          human_file_pattern=\"_1x02nguL_\", foreign_species='Saccharomyces cerevisiae', q_value=0.025, rt_delta=kelly_rt)\n",
    "\n",
    "\n",
    "kelly_dd_5 = get_fdp_flash(o_peaks_path =  kelly_path + \"SingleCell_QuantResults-FlashLFQ_PIP-ECHO\\\\FlashLFQ_7772_DonorPepQ_1\\QuantifiedPeaks.tsv\",\n",
    "                          c_peaks_path = kelly_path + \"SingleCell_QuantResults-FlashLFQ_PIP-ECHO\\\\CensoredData_FlashLFQ_7772_DonorPepQ_1\\QuantifiedPeaks.tsv\",\n",
    "                          censored_psm_path = kelly_censored_psms,\n",
    "                          human_file_pattern=\"_1x02nguL_\", foreign_species='Saccharomyces cerevisiae', q_value=0.05, rt_delta=kelly_rt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\PIP_ECHO_PRIDE\\\\SingleCellDataset\\\\SingleCell_Results-FragPipe\\\\LibrarySettings_1Percent\\\\experiment_annotation.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 40\u001b[0m\n\u001b[0;32m     26\u001b[0m inhouse_iq_2p5 \u001b[38;5;241m=\u001b[39m get_fdp_fragger(o_folder \u001b[38;5;241m=\u001b[39m inhouse_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEcoli_Results-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mIonQuant_2p5Percent_50PercentEntrapmentDb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     27\u001b[0m                             c_folder\u001b[38;5;241m=\u001b[39m inhouse_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEcoli_Results-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCensoredData_IonQuant_2p5Percent_50PercentEntrapmentDb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m                             censored_psm_path\u001b[38;5;241m=\u001b[39m inhouse_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEcoli_CensoredFiles-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCensoredPsms.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     29\u001b[0m                             human_file_pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Human_C18_\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m                             foreign_species\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mECOLI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m                             rt_diff_threshold\u001b[38;5;241m=\u001b[39minhouse_rt)\n\u001b[0;32m     33\u001b[0m inhouse_iq_5 \u001b[38;5;241m=\u001b[39m get_fdp_fragger(o_folder \u001b[38;5;241m=\u001b[39m inhouse_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEcoli_Results-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mIonQuant_5Percent_50PercentEntrapmentDb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     34\u001b[0m                             c_folder\u001b[38;5;241m=\u001b[39m inhouse_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEcoli_Results-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCensoredData_IonQuant_5Percent_50PercentEntrapmentDb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m                             censored_psm_path\u001b[38;5;241m=\u001b[39m inhouse_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEcoli_CensoredFiles-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCensoredPsms.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     36\u001b[0m                             human_file_pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Human_C18_\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m                             foreign_species\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mECOLI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m                             rt_diff_threshold\u001b[38;5;241m=\u001b[39minhouse_rt)\n\u001b[1;32m---> 40\u001b[0m kelly_iq_1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_fdp_fragger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkelly_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSingleCell_Results-FragPipe\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mLibrarySettings_1Percent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mc_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkelly_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSingleCell_Results-FragPipe\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mLibrarySettings_CensoredData_1Percent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcensored_psm_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkelly_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCensoredFiles-FragPipe\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mCensoredPsms.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mhuman_file_pattern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_1x02nguL_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mrt_diff_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkelly_rt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m kelly_iq_2p5 \u001b[38;5;241m=\u001b[39m get_fdp_fragger(o_folder \u001b[38;5;241m=\u001b[39m kelly_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleCell_Results-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLibrarySettings_2p5Percent_2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     47\u001b[0m                             c_folder\u001b[38;5;241m=\u001b[39m kelly_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleCell_Results-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLibrarySettings_CensoredData_2p5Percent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m                             censored_psm_path\u001b[38;5;241m=\u001b[39m kelly_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCensoredFiles-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCensoredPsms.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \n\u001b[0;32m     49\u001b[0m                             human_file_pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_1x02nguL_\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     50\u001b[0m                             rt_diff_threshold\u001b[38;5;241m=\u001b[39mkelly_rt)\n\u001b[0;32m     52\u001b[0m kelly_iq_5 \u001b[38;5;241m=\u001b[39m get_fdp_fragger(o_folder \u001b[38;5;241m=\u001b[39m kelly_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleCell_Results-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLibrarySettings_5Percent_2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     53\u001b[0m                             c_folder\u001b[38;5;241m=\u001b[39m kelly_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleCell_Results-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLibrarySettings_CensoredData_5Percent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m                             censored_psm_path\u001b[38;5;241m=\u001b[39m kelly_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCensoredFiles-FragPipe\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCensoredPsms.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \n\u001b[0;32m     55\u001b[0m                             human_file_pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_1x02nguL_\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     56\u001b[0m                             rt_diff_threshold\u001b[38;5;241m=\u001b[39mkelly_rt)\n",
      "Cell \u001b[1;32mIn[64], line 10\u001b[0m, in \u001b[0;36mget_fdp_fragger\u001b[1;34m(o_folder, c_folder, censored_psm_path, foreign_species, human_file_pattern, rt_diff_threshold)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_fdp_fragger\u001b[39m(o_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGygiTwoProteome_PXD014415\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIonQuant1Percent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      2\u001b[0m                       c_folder\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGygiTwoProteome_PXD014415\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIonQuant1Percent_censored\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m                       censored_psm_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGygiTwoProteome_PXD014415\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCensoredDataFiles_fragger\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCensoredPsms.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                       foreign_species \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYEAST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m                       human_file_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_human_90min_\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m                       rt_diff_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m      8\u001b[0m         rt_diff_threshold \u001b[38;5;241m=\u001b[39m rt_diff_threshold \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;66;03m# Convert to seconds, which is how iq stores RT\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m         human_rep_indices \u001b[38;5;241m=\u001b[39m \u001b[43mget_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuman_file_pattern\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m         human_rep_indices_censored \u001b[38;5;241m=\u001b[39m get_indices(c_folder, human_file_pattern)\n\u001b[0;32m     13\u001b[0m         ion_count \u001b[38;5;241m=\u001b[39m count_ions_by_species(o_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcombined_modified_peptide.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m, match_indices \u001b[38;5;241m=\u001b[39m human_rep_indices, foreign_species \u001b[38;5;241m=\u001b[39m foreign_species)\n",
      "Cell \u001b[1;32mIn[64], line 36\u001b[0m, in \u001b[0;36mget_indices\u001b[1;34m(folder_path, pattern)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_indices\u001b[39m(folder_path, pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_human_90min_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     35\u001b[0m     exp_file_path \u001b[38;5;241m=\u001b[39m folder_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mexperiment_annotation.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 36\u001b[0m     exp_file \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     human_indices \u001b[38;5;241m=\u001b[39m exp_file[exp_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(pattern)]\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m human_indices\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\PIP_ECHO_PRIDE\\\\SingleCellDataset\\\\SingleCell_Results-FragPipe\\\\LibrarySettings_1Percent\\\\experiment_annotation.tsv'"
     ]
    }
   ],
   "source": [
    "gygi_iq_1 = get_fdp_fragger(o_folder =  gygi_path + \"Lim_Results-FragPipe\\\\IonQuant_1Percent_50PercentEntrapmentDb\",\n",
    "                                c_folder= gygi_path + \"Lim_Results-FragPipe\\\\CensoredData_IonQuant_1Percent_50PercentEntrapmentDb\",\n",
    "                                censored_psm_path= gygi_path + \"CensoredFiles-FragPipe\\\\CensoredPsms.tsv\",\n",
    "                                human_file_pattern=\"human_90\",\n",
    "                                rt_diff_threshold=gygi_rt)\n",
    "\n",
    "gygi_iq_2p5 = get_fdp_fragger(o_folder =  gygi_path + \"Lim_Results-FragPipe\\\\IonQuant_2p5Percent_50PercentEntrapmentDb\",\n",
    "                                c_folder= gygi_path + \"Lim_Results-FragPipe\\\\CensoredData_IonQuant_2p5Percent_50PercentEntrapmentDb\",\n",
    "                                censored_psm_path= gygi_path + \"CensoredFiles-FragPipe\\\\CensoredPsms.tsv\",\n",
    "                                human_file_pattern=\"human_90\",\n",
    "                                rt_diff_threshold=gygi_rt) \n",
    "\n",
    "gygi_iq_5 = get_fdp_fragger(o_folder =  gygi_path + \"Lim_Results-FragPipe\\\\IonQuant_5Percent_50PercentEntrapmentDb\",\n",
    "                                c_folder= gygi_path + \"Lim_Results-FragPipe\\\\CensoredData_IonQuant_5Percent_50PercentEntrapmentDb\",\n",
    "                                censored_psm_path= gygi_path + \"CensoredFiles-FragPipe\\\\CensoredPsms.tsv\",\n",
    "                                human_file_pattern=\"human_90\",\n",
    "                                rt_diff_threshold=gygi_rt)\n",
    "\n",
    "inhouse_iq_1 = get_fdp_fragger(o_folder = inhouse_path + \"Ecoli_Results-FragPipe\\\\IonQuant_1Percent_50PercentEntrapmentDb\", \n",
    "                            c_folder= inhouse_path + \"Ecoli_Results-FragPipe\\\\CensoredData_IonQuant_1Percent_50PercentEntrapmentDb\",\n",
    "                            censored_psm_path= inhouse_path + \"Ecoli_CensoredFiles-FragPipe\\\\CensoredPsms.tsv\", \n",
    "                            human_file_pattern=\"_Human_C18_\",\n",
    "                            foreign_species=\"ECOLI\",\n",
    "                            rt_diff_threshold=inhouse_rt)\n",
    "\n",
    "inhouse_iq_2p5 = get_fdp_fragger(o_folder = inhouse_path + \"Ecoli_Results-FragPipe\\\\IonQuant_2p5Percent_50PercentEntrapmentDb\", \n",
    "                            c_folder= inhouse_path + \"Ecoli_Results-FragPipe\\\\CensoredData_IonQuant_2p5Percent_50PercentEntrapmentDb\",\n",
    "                            censored_psm_path= inhouse_path + \"Ecoli_CensoredFiles-FragPipe\\\\CensoredPsms.tsv\", \n",
    "                            human_file_pattern=\"_Human_C18_\",\n",
    "                            foreign_species=\"ECOLI\",\n",
    "                            rt_diff_threshold=inhouse_rt)\n",
    "\n",
    "inhouse_iq_5 = get_fdp_fragger(o_folder = inhouse_path + \"Ecoli_Results-FragPipe\\\\IonQuant_5Percent_50PercentEntrapmentDb\", \n",
    "                            c_folder= inhouse_path + \"Ecoli_Results-FragPipe\\\\CensoredData_IonQuant_5Percent_50PercentEntrapmentDb\",\n",
    "                            censored_psm_path= inhouse_path + \"Ecoli_CensoredFiles-FragPipe\\\\CensoredPsms.tsv\", \n",
    "                            human_file_pattern=\"_Human_C18_\",\n",
    "                            foreign_species=\"ECOLI\",\n",
    "                            rt_diff_threshold=inhouse_rt)\n",
    "\n",
    "kelly_iq_1 = get_fdp_fragger(o_folder = kelly_path + \"SingleCell_Results-FragPipe\\\\LibrarySettings_1Percent\", \n",
    "                            c_folder= kelly_path + \"SingleCell_Results-FragPipe\\\\LibrarySettings_CensoredData_1Percent\",\n",
    "                            censored_psm_path= kelly_path + \"CensoredFiles-FragPipe\\\\CensoredPsms.tsv\", \n",
    "                            human_file_pattern=\"_1x02nguL_\",\n",
    "                            rt_diff_threshold=kelly_rt)\n",
    "\n",
    "kelly_iq_2p5 = get_fdp_fragger(o_folder = kelly_path + \"SingleCell_Results-FragPipe\\\\LibrarySettings_2p5Percent_2\", \n",
    "                            c_folder= kelly_path + \"SingleCell_Results-FragPipe\\\\LibrarySettings_CensoredData_2p5Percent\",\n",
    "                            censored_psm_path= kelly_path + \"CensoredFiles-FragPipe\\\\CensoredPsms.tsv\",  \n",
    "                            human_file_pattern=\"_1x02nguL_\",\n",
    "                            rt_diff_threshold=kelly_rt)\n",
    "\n",
    "kelly_iq_5 = get_fdp_fragger(o_folder = kelly_path + \"SingleCell_Results-FragPipe\\\\LibrarySettings_5Percent_2\", \n",
    "                            c_folder= kelly_path + \"SingleCell_Results-FragPipe\\\\LibrarySettings_CensoredData_5Percent\",\n",
    "                            censored_psm_path= kelly_path + \"CensoredFiles-FragPipe\\\\CensoredPsms.tsv\",  \n",
    "                            human_file_pattern=\"_1x02nguL_\",\n",
    "                            rt_diff_threshold=kelly_rt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\3751629822.py:19: DtypeWarning: Columns (51,52,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  evidence = pd.read_csv(evidence_path, sep = '\\t')\n",
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_63072\\3751629822.py:19: DtypeWarning: Columns (49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  evidence = pd.read_csv(evidence_path, sep = '\\t')\n"
     ]
    }
   ],
   "source": [
    "gygi_mq = get_fdp_maxquant(gygi_path + \"Lim_Results-MaxQuant\\\\txt\\\\evidence.txt\", \"Yeast\", human_file_pattern=\"human_90\")\n",
    "\n",
    "inhouse_mq = get_fdp_maxquant(inhouse_path + \"Ecoli_Results-MaxQuant\\\\txt\\\\evidence.txt\", \"Ecoli\", human_file_pattern=\"_Human_C18_\")\n",
    "\n",
    "kelly_mq = get_fdp_maxquant(kelly_path + \"SingleCell_Results-MaxQuant\\\\txt\\\\evidence.txt\", \"Yeast\", human_file_pattern=\"_1x02nguL_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Gygi_Flash_v1\" : pd.Series(gygi_flashv1),\n",
    "        \"Gygi_Flash_v2_1\" : pd.Series(gygi_dd_1),\n",
    "        \"Gygi_Flash_v2_2.5\" : pd.Series(gygi_dd_2p5),\n",
    "        \"Gygi_Flash_v2_5\" : pd.Series(gygi_dd_5),\n",
    "        \"Gygi_IonQuant_1\" : pd.Series(gygi_iq_1),\n",
    "        \"Gygi_IonQuant_2.5\" : pd.Series(gygi_iq_2p5),\n",
    "        \"Gygi_IonQuant_5\" : pd.Series(gygi_iq_5),\n",
    "        \"Gygi_MaxQuant\" : pd.Series(gygi_mq),\n",
    "\n",
    "        \"Kelly_Flash_v1\" : pd.Series(kelly_flashv1),\n",
    "        \"Kelly_Flash_v2_1\" : pd.Series(kelly_dd_1),\n",
    "        \"Kelly_Flash_v2_2.5\" : pd.Series(kelly_dd_2p5),\n",
    "        \"Kelly_Flash_v2_5\" : pd.Series(kelly_dd_5),\n",
    "        \"Kelly_IonQuant_1\" : pd.Series(kelly_iq_1),\n",
    "        \"Kelly_IonQuant_2.5\" : pd.Series(kelly_iq_2p5),\n",
    "        \"Kelly_IonQuant_5\" : pd.Series(kelly_iq_5),\n",
    "        \"Kelly_MaxQuant\" : pd.Series(kelly_mq),\n",
    "\n",
    "        \"Inhouse_Flash_v1\" : pd.Series(inhouse_flashv1),\n",
    "        \"Inhouse_Flash_v2_1\" : pd.Series(inhouse_dd_1),\n",
    "        \"Inhouse_Flash_v2_2.5\" : pd.Series(inhouse_dd_2p5),\n",
    "        \"Inhouse_Flash_v2_5\" : pd.Series(inhouse_dd_5),\n",
    "        \"Inhouse_IonQuant_1\" : pd.Series(inhouse_iq_1),\n",
    "        \"Inhouse_IonQuant_2.5\" : pd.Series(inhouse_iq_2p5),\n",
    "        \"Inhouse_IonQuant_5\" : pd.Series(inhouse_iq_5),\n",
    "        \"Inhouse_MaxQuant\" : pd.Series(inhouse_mq)\n",
    "    }\n",
    ")\n",
    "\n",
    "fdp_df = fdp_df.transpose()\n",
    "fdp_df[\"software\"] = fdp_df.index\n",
    "\n",
    "fdp_df.to_csv(r\"C:\\Users\\Alex\\Source\\Repos\\MBR_metamorpheus\\R_Files\\FDP_Analysis_Results.tsv\", sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
